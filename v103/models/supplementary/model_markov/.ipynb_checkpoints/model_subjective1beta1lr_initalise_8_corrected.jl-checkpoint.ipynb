{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model subjective 1 beta 1 lr\n",
    "\n",
    "#### This model has one beta \n",
    "#### Also has an intercept\n",
    "\n",
    "#### one learning rate (no distinciton between appetative/aversive updates)\n",
    "\n",
    "#### Uses Q learned average to predict choice\n",
    "\n",
    "#### NJG, 14th November 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up commands/load relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set everything up\n",
    "parallel = true # Run on multiple CPUs. If you are having trouble, set parallel = false: easier to debug\n",
    "\n",
    "# this activates the multiprocessing threads\n",
    "if (parallel)\n",
    "\t# only run this once\n",
    "addprocs(4)\n",
    "end\n",
    "\n",
    "# load required libraries\n",
    "\n",
    "@everywhere using DataFrames\n",
    "@everywhere using DataArrays\n",
    "@everywhere using ForwardDiff\n",
    "@everywhere using PyCall\n",
    "@everywhere using Distributions\n",
    "@everywhere using PyPlot\n",
    "\n",
    "@everywhere PyCall.@pyimport scipy.optimize as so\n",
    "\n",
    "# this is the code for the actual fitting routines\n",
    "@everywhere include(\"em.jl\")\n",
    "@everywhere include(\"common.jl\")\n",
    "@everywhere include(\"likfuns.jl\")\n",
    "\n",
    "# this is generates starting matricies for betas, sigmas etc to feed into model\n",
    "@everywhere include(\"genVars.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in task data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mreadtable is deprecated, use CSV.read from the CSV package instead\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1m#readtable#191\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Bool, ::Char, ::Array{Char,1}, ::Char, ::Array{String,1}, ::Array{String,1}, ::Array{String,1}, ::Bool, ::Int64, ::Array{Symbol,1}, ::Array{Any,1}, ::Bool, ::Char, ::Bool, ::Int64, ::Array{Int64,1}, ::Bool, ::Symbol, ::Bool, ::Bool, ::DataFrames.#readtable, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/DataFrames/src/deprecated.jl:1045\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mreadtable\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/DataFrames/src/deprecated.jl:1045\u001b[22m\u001b[22m\n",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m\n",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/Compat/src/Compat.jl:174\u001b[22m\u001b[22m\n",
      " [6] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/IJulia/src/execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [7] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [8] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[2], in expression starting on line 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sub_no</th><th>exclude</th><th>trial_index</th><th>trial_index_per_block</th><th>block</th><th>rank</th><th>reward</th><th>delay</th><th>reward_z</th><th>delay_z</th><th>profitability</th><th>profitability_zscored</th><th>approach_avoid</th><th>rt</th><th>rt_z</th><th>force_trial</th><th>missed</th><th>order_condition</th><th>rank_prev_t</th><th>reward_prev_t</th><th>reward_prev_t_zscored</th><th>delay_prev_t</th><th>delay_prev_t_zscored</th><th>accept_reject_prev_t</th><th>force_prev_t</th><th>profitability_prev_t</th><th>profitability_2back</th><th>average_reward_2back</th><th>average_delay_2back</th><th>average_reward_3back</th><th>average_delay_3back</th><th>average_reward_4back</th><th>average_delay_4back</th><th>average_reward_5back</th><th>average_delay_5back</th><th>average_reward_10back</th><th>average_delay_10back</th><th>running_average_rl_exc_present_option_alpha_03</th><th>running_average_rl_exc_present_option_alpha_01</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>4</td><td>20</td><td>8</td><td>-1.0081</td><td>1.0081</td><td>2.5</td><td>-0.941004</td><td>-1.0</td><td>1172</td><td>1.4718</td><td>0</td><td>0</td><td>2</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>80</td><td>2</td><td>0.989683</td><td>-0.989683</td><td>40.0</td><td>1.3054</td><td>1.0</td><td>1046</td><td>0.844306</td><td>1</td><td>0</td><td>2</td><td>4.0</td><td>20.0</td><td>-1.0081</td><td>8.0</td><td>1.0081</td><td>-1.0</td><td>0.0</td><td>2.5</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.3675</td><td>0.2025</td></tr><tr><th>3</th><td>1</td><td>0</td><td>2</td><td>2</td><td>1</td><td>3</td><td>80</td><td>8</td><td>0.989683</td><td>1.0081</td><td>10.0</td><td>-0.491724</td><td>1.0</td><td>743</td><td>-0.664676</td><td>0</td><td>0</td><td>2</td><td>1.0</td><td>80.0</td><td>0.989683</td><td>2.0</td><td>-0.989683</td><td>1.0</td><td>1.0</td><td>40.0</td><td>2.5</td><td>50.0</td><td>5.0</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>6.00605</td><td>3.38762</td></tr><tr><th>4</th><td>1</td><td>0</td><td>3</td><td>3</td><td>1</td><td>4</td><td>20</td><td>8</td><td>-1.0081</td><td>1.0081</td><td>2.5</td><td>-0.941004</td><td>NaN</td><td>533</td><td>-1.71051</td><td>1</td><td>1</td><td>2</td><td>3.0</td><td>80.0</td><td>0.989683</td><td>8.0</td><td>1.0081</td><td>1.0</td><td>0.0</td><td>10.0</td><td>40.0</td><td>80.0</td><td>5.0</td><td>60.0</td><td>6.0</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>3.53008</td><td>3.27958</td></tr><tr><th>5</th><td>1</td><td>0</td><td>4</td><td>4</td><td>1</td><td>4</td><td>20</td><td>8</td><td>-1.0081</td><td>1.0081</td><td>2.5</td><td>-0.941004</td><td>1.0</td><td>858</td><td>-0.0919604</td><td>0</td><td>0</td><td>2</td><td>4.0</td><td>20.0</td><td>-1.0081</td><td>8.0</td><td>1.0081</td><td>NaN</td><td>1.0</td><td>2.5</td><td>10.0</td><td>50.0</td><td>8.0</td><td>60.0</td><td>6.0</td><td>50.0</td><td>6.5</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>1.57832</td><td>2.59331</td></tr><tr><th>6</th><td>1</td><td>0</td><td>5</td><td>5</td><td>1</td><td>2</td><td>20</td><td>2</td><td>-1.0081</td><td>-0.989683</td><td>10.0</td><td>-0.491724</td><td>1.0</td><td>818</td><td>-0.291166</td><td>0</td><td>0</td><td>2</td><td>4.0</td><td>20.0</td><td>-1.0081</td><td>8.0</td><td>1.0081</td><td>1.0</td><td>0.0</td><td>2.5</td><td>2.5</td><td>20.0</td><td>8.0</td><td>40.0</td><td>8.0</td><td>50.0</td><td>6.5</td><td>44.0</td><td>6.8</td><td>NaN</td><td>NaN</td><td>0.908862</td><td>2.09302</td></tr></tbody></table>"
      ],
      "text/plain": [
       "6×39 DataFrames.DataFrame. Omitted printing of 33 columns\n",
       "│ Row │ sub_no │ exclude │ trial_index │ trial_index_per_block │ block │ rank │\n",
       "├─────┼────────┼─────────┼─────────────┼───────────────────────┼───────┼──────┤\n",
       "│ 1   │ 1      │ 0       │ 0           │ 0                     │ 1     │ 4    │\n",
       "│ 2   │ 1      │ 0       │ 1           │ 1                     │ 1     │ 1    │\n",
       "│ 3   │ 1      │ 0       │ 2           │ 2                     │ 1     │ 3    │\n",
       "│ 4   │ 1      │ 0       │ 3           │ 3                     │ 1     │ 4    │\n",
       "│ 5   │ 1      │ 0       │ 4           │ 4                     │ 1     │ 4    │\n",
       "│ 6   │ 1      │ 0       │ 5           │ 5                     │ 1     │ 2    │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv file of the data\n",
    "df = readtable(\"/Users/neil/Dropbox/Daw_Lab/PreySelection/v103/data/subject_data_excluded_deleted.csv\")\n",
    "\n",
    "#note will include force trials and missed responses \n",
    "\n",
    "#display header\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append data with the column \"sub\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sub_no</th><th>exclude</th><th>trial_index</th><th>trial_index_per_block</th><th>block</th><th>rank</th><th>reward</th><th>delay</th><th>reward_z</th><th>delay_z</th><th>profitability</th><th>profitability_zscored</th><th>approach_avoid</th><th>rt</th><th>rt_z</th><th>force_trial</th><th>missed</th><th>order_condition</th><th>rank_prev_t</th><th>reward_prev_t</th><th>reward_prev_t_zscored</th><th>delay_prev_t</th><th>delay_prev_t_zscored</th><th>accept_reject_prev_t</th><th>force_prev_t</th><th>profitability_prev_t</th><th>profitability_2back</th><th>average_reward_2back</th><th>average_delay_2back</th><th>average_reward_3back</th><th>average_delay_3back</th><th>average_reward_4back</th><th>average_delay_4back</th><th>average_reward_5back</th><th>average_delay_5back</th><th>average_reward_10back</th><th>average_delay_10back</th><th>running_average_rl_exc_present_option_alpha_03</th><th>running_average_rl_exc_present_option_alpha_01</th><th>sub</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>4</td><td>20</td><td>8</td><td>-1.0081</td><td>1.0081</td><td>2.5</td><td>-0.941004</td><td>-1.0</td><td>1172</td><td>1.4718</td><td>0</td><td>0</td><td>2</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.0</td><td>0.0</td><td>1</td></tr><tr><th>2</th><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>80</td><td>2</td><td>0.989683</td><td>-0.989683</td><td>40.0</td><td>1.3054</td><td>1.0</td><td>1046</td><td>0.844306</td><td>1</td><td>0</td><td>2</td><td>4.0</td><td>20.0</td><td>-1.0081</td><td>8.0</td><td>1.0081</td><td>-1.0</td><td>0.0</td><td>2.5</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.3675</td><td>0.2025</td><td>1</td></tr><tr><th>3</th><td>1</td><td>0</td><td>2</td><td>2</td><td>1</td><td>3</td><td>80</td><td>8</td><td>0.989683</td><td>1.0081</td><td>10.0</td><td>-0.491724</td><td>1.0</td><td>743</td><td>-0.664676</td><td>0</td><td>0</td><td>2</td><td>1.0</td><td>80.0</td><td>0.989683</td><td>2.0</td><td>-0.989683</td><td>1.0</td><td>1.0</td><td>40.0</td><td>2.5</td><td>50.0</td><td>5.0</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>6.00605</td><td>3.38762</td><td>1</td></tr><tr><th>4</th><td>1</td><td>0</td><td>3</td><td>3</td><td>1</td><td>4</td><td>20</td><td>8</td><td>-1.0081</td><td>1.0081</td><td>2.5</td><td>-0.941004</td><td>NaN</td><td>533</td><td>-1.71051</td><td>1</td><td>1</td><td>2</td><td>3.0</td><td>80.0</td><td>0.989683</td><td>8.0</td><td>1.0081</td><td>1.0</td><td>0.0</td><td>10.0</td><td>40.0</td><td>80.0</td><td>5.0</td><td>60.0</td><td>6.0</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>3.53008</td><td>3.27958</td><td>1</td></tr><tr><th>5</th><td>1</td><td>0</td><td>4</td><td>4</td><td>1</td><td>4</td><td>20</td><td>8</td><td>-1.0081</td><td>1.0081</td><td>2.5</td><td>-0.941004</td><td>1.0</td><td>858</td><td>-0.0919604</td><td>0</td><td>0</td><td>2</td><td>4.0</td><td>20.0</td><td>-1.0081</td><td>8.0</td><td>1.0081</td><td>NaN</td><td>1.0</td><td>2.5</td><td>10.0</td><td>50.0</td><td>8.0</td><td>60.0</td><td>6.0</td><td>50.0</td><td>6.5</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>1.57832</td><td>2.59331</td><td>1</td></tr><tr><th>6</th><td>1</td><td>0</td><td>5</td><td>5</td><td>1</td><td>2</td><td>20</td><td>2</td><td>-1.0081</td><td>-0.989683</td><td>10.0</td><td>-0.491724</td><td>1.0</td><td>818</td><td>-0.291166</td><td>0</td><td>0</td><td>2</td><td>4.0</td><td>20.0</td><td>-1.0081</td><td>8.0</td><td>1.0081</td><td>1.0</td><td>0.0</td><td>2.5</td><td>2.5</td><td>20.0</td><td>8.0</td><td>40.0</td><td>8.0</td><td>50.0</td><td>6.5</td><td>44.0</td><td>6.8</td><td>NaN</td><td>NaN</td><td>0.908862</td><td>2.09302</td><td>1</td></tr></tbody></table>"
      ],
      "text/plain": [
       "6×40 DataFrames.DataFrame. Omitted printing of 34 columns\n",
       "│ Row │ sub_no │ exclude │ trial_index │ trial_index_per_block │ block │ rank │\n",
       "├─────┼────────┼─────────┼─────────────┼───────────────────────┼───────┼──────┤\n",
       "│ 1   │ 1      │ 0       │ 0           │ 0                     │ 1     │ 4    │\n",
       "│ 2   │ 1      │ 0       │ 1           │ 1                     │ 1     │ 1    │\n",
       "│ 3   │ 1      │ 0       │ 2           │ 2                     │ 1     │ 3    │\n",
       "│ 4   │ 1      │ 0       │ 3           │ 3                     │ 1     │ 4    │\n",
       "│ 5   │ 1      │ 0       │ 4           │ 4                     │ 1     │ 4    │\n",
       "│ 6   │ 1      │ 0       │ 5           │ 5                     │ 1     │ 2    │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is just a replica of the existing column sub_no but think em looks for \"sub\" specifically\n",
    "df[:sub] = df[:sub_no]\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take out missed responses\n",
    "#### note: you will need to account for these at a later point as missing repsonses imposes a time delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sub_no</th><th>exclude</th><th>trial_index</th><th>trial_index_per_block</th><th>block</th><th>rank</th><th>reward</th><th>delay</th><th>reward_z</th><th>delay_z</th><th>profitability</th><th>profitability_zscored</th><th>approach_avoid</th><th>rt</th><th>rt_z</th><th>force_trial</th><th>missed</th><th>order_condition</th><th>rank_prev_t</th><th>reward_prev_t</th><th>reward_prev_t_zscored</th><th>delay_prev_t</th><th>delay_prev_t_zscored</th><th>accept_reject_prev_t</th><th>force_prev_t</th><th>profitability_prev_t</th><th>profitability_2back</th><th>average_reward_2back</th><th>average_delay_2back</th><th>average_reward_3back</th><th>average_delay_3back</th><th>average_reward_4back</th><th>average_delay_4back</th><th>average_reward_5back</th><th>average_delay_5back</th><th>average_reward_10back</th><th>average_delay_10back</th><th>running_average_rl_exc_present_option_alpha_03</th><th>running_average_rl_exc_present_option_alpha_01</th><th>sub</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>4</td><td>20</td><td>8</td><td>-1.0081</td><td>1.0081</td><td>2.5</td><td>-0.941004</td><td>-1.0</td><td>1172</td><td>1.4718</td><td>0</td><td>0</td><td>2</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.0</td><td>0.0</td><td>1</td></tr><tr><th>2</th><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>80</td><td>2</td><td>0.989683</td><td>-0.989683</td><td>40.0</td><td>1.3054</td><td>1.0</td><td>1046</td><td>0.844306</td><td>1</td><td>0</td><td>2</td><td>4.0</td><td>20.0</td><td>-1.0081</td><td>8.0</td><td>1.0081</td><td>-1.0</td><td>0.0</td><td>2.5</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.3675</td><td>0.2025</td><td>1</td></tr><tr><th>3</th><td>1</td><td>0</td><td>2</td><td>2</td><td>1</td><td>3</td><td>80</td><td>8</td><td>0.989683</td><td>1.0081</td><td>10.0</td><td>-0.491724</td><td>1.0</td><td>743</td><td>-0.664676</td><td>0</td><td>0</td><td>2</td><td>1.0</td><td>80.0</td><td>0.989683</td><td>2.0</td><td>-0.989683</td><td>1.0</td><td>1.0</td><td>40.0</td><td>2.5</td><td>50.0</td><td>5.0</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>6.00605</td><td>3.38762</td><td>1</td></tr><tr><th>4</th><td>1</td><td>0</td><td>4</td><td>4</td><td>1</td><td>4</td><td>20</td><td>8</td><td>-1.0081</td><td>1.0081</td><td>2.5</td><td>-0.941004</td><td>1.0</td><td>858</td><td>-0.0919604</td><td>0</td><td>0</td><td>2</td><td>4.0</td><td>20.0</td><td>-1.0081</td><td>8.0</td><td>1.0081</td><td>NaN</td><td>1.0</td><td>2.5</td><td>10.0</td><td>50.0</td><td>8.0</td><td>60.0</td><td>6.0</td><td>50.0</td><td>6.5</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>1.57832</td><td>2.59331</td><td>1</td></tr><tr><th>5</th><td>1</td><td>0</td><td>5</td><td>5</td><td>1</td><td>2</td><td>20</td><td>2</td><td>-1.0081</td><td>-0.989683</td><td>10.0</td><td>-0.491724</td><td>1.0</td><td>818</td><td>-0.291166</td><td>0</td><td>0</td><td>2</td><td>4.0</td><td>20.0</td><td>-1.0081</td><td>8.0</td><td>1.0081</td><td>1.0</td><td>0.0</td><td>2.5</td><td>2.5</td><td>20.0</td><td>8.0</td><td>40.0</td><td>8.0</td><td>50.0</td><td>6.5</td><td>44.0</td><td>6.8</td><td>NaN</td><td>NaN</td><td>0.908862</td><td>2.09302</td><td>1</td></tr><tr><th>6</th><td>1</td><td>0</td><td>6</td><td>6</td><td>1</td><td>4</td><td>20</td><td>8</td><td>-1.0081</td><td>1.0081</td><td>2.5</td><td>-0.941004</td><td>1.0</td><td>1076</td><td>0.99371</td><td>0</td><td>0</td><td>2</td><td>2.0</td><td>20.0</td><td>-1.0081</td><td>2.0</td><td>-0.989683</td><td>1.0</td><td>0.0</td><td>10.0</td><td>2.5</td><td>20.0</td><td>5.0</td><td>20.0</td><td>6.0</td><td>35.0</td><td>6.5</td><td>44.0</td><td>5.6</td><td>NaN</td><td>NaN</td><td>1.78174</td><td>2.33581</td><td>1</td></tr></tbody></table>"
      ],
      "text/plain": [
       "6×40 DataFrames.DataFrame. Omitted printing of 34 columns\n",
       "│ Row │ sub_no │ exclude │ trial_index │ trial_index_per_block │ block │ rank │\n",
       "├─────┼────────┼─────────┼─────────────┼───────────────────────┼───────┼──────┤\n",
       "│ 1   │ 1      │ 0       │ 0           │ 0                     │ 1     │ 4    │\n",
       "│ 2   │ 1      │ 0       │ 1           │ 1                     │ 1     │ 1    │\n",
       "│ 3   │ 1      │ 0       │ 2           │ 2                     │ 1     │ 3    │\n",
       "│ 4   │ 1      │ 0       │ 4           │ 4                     │ 1     │ 4    │\n",
       "│ 5   │ 1      │ 0       │ 5           │ 5                     │ 1     │ 2    │\n",
       "│ 6   │ 1      │ 0       │ 6           │ 6                     │ 1     │ 4    │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exclude missed responses\n",
    "df = df[df[:missed].==0,:]\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model: \"subjective\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere function model_subjective(params, data)\n",
    "        \n",
    "    intercept = params[1]\n",
    "    beta = params[2]\n",
    "    lr = 0.5 + 0.5*erf(params[3]/sqrt(2))\n",
    "    \n",
    "    #Q_av estimates reward in the environment\n",
    "    Q_av_per_time = zeros(typeof(beta),1)\n",
    "    delay_sum = zeros(typeof(beta),1)\n",
    "    reward_sum = zeros(typeof(beta),1)\n",
    "    opp_cost = zeros(typeof(beta),1)\n",
    "    \n",
    "    Q_estimate = zeros(typeof(beta),1) + 8\n",
    "    opp_cost_estimate = zeros(typeof(beta),1)\n",
    "    \n",
    "    Qd = zeros(typeof(beta),2)\n",
    "\n",
    "    #initalise likelihood value\n",
    "    lik = 0\n",
    "    \n",
    "    reward = data[:reward]\n",
    "    delay = data[:delay]\n",
    "    force = data[:force_trial] \n",
    "    t = data[:trial_index] # trial \n",
    "    sub = data[:sub_no] # subject number\n",
    "    block = data[:block] # block\n",
    "    \n",
    "    c = data[:approach_avoid]\n",
    "    \n",
    "    #convert data to 1s (=avoid) and 2s (=approach); \n",
    "    # 1 (previously -1) is going to index choice to go with opportunity cost, \n",
    "    # 2 (previously +1) to go with the reward of the encountered option\n",
    "    c = c+1;\n",
    "    c_index_avoid = find(c.==0)\n",
    "    c[c_index_avoid] = 1\n",
    "        \n",
    "    #must convert floats (i.e. decimals) to integers in order to use as an index\n",
    "   c = convert(DataVector{Integer}, c)\n",
    "\n",
    "    \n",
    "    reward_sum_store = [];\n",
    "    delay_sum_store = [];\n",
    "    av_reward_store = [];\n",
    "    opp_cost_store  = []; \n",
    "    opp_cost_estimate_store = [];\n",
    "    Q_estimate_store = [];\n",
    "    \n",
    "    for i = 1:length(c)\n",
    "        \n",
    "            # 2 seconds without reward on each trial regadless of accept/reject\n",
    "            delay_sum += 2;\n",
    "         \n",
    "            # calculate current (arithmetic) reward per second from number of seconds elapsed and reward accured\n",
    "            Q_av_per_time = reward_sum./delay_sum\n",
    "            opp_cost = Q_av_per_time*delay[i]\n",
    "        \n",
    "            Q_estimate = (1-lr) * Q_estimate + 0\n",
    "            Q_estimate = (1-lr) * Q_estimate + 0\n",
    "        \n",
    "            opp_cost_estimate = Q_estimate*delay[i]\n",
    "\n",
    "            append!(reward_sum_store, reward_sum)\n",
    "            append!(delay_sum_store, delay_sum)\n",
    "            append!(av_reward_store, Q_av_per_time)\n",
    "            append!(opp_cost_store, opp_cost)\n",
    "            append!(opp_cost_estimate_store, opp_cost_estimate)\n",
    "            append!(Q_estimate_store, Q_estimate)\n",
    "        \n",
    "            # if not a force trial predict choice based on current values\n",
    "            if (force[i]<1)\n",
    "                        \n",
    "                # decision variable - the estimate of opportunity cost (\"reward\" of rejecting) versus \n",
    "                # reward of the current option (if accepted)\n",
    "                Qd = [intercept, 0] + [beta.*opp_cost_estimate[1], beta.*reward[i]]\n",
    "\n",
    "                # increment likelihood\n",
    "                lik += Qd[c[i]] - log(sum(exp.(Qd)))\n",
    "            \n",
    "            end\n",
    "        \n",
    "            # regardless of whether a force trial or not, \n",
    "            # if accept the option, Qreward updates and there is a longer period of delay\n",
    "            if (c[i] == 2)\n",
    "                \n",
    "                delay_sum += delay[i]\n",
    "                reward_sum += reward[i]\n",
    "            \n",
    "                for i = 1:length(delay[i])\n",
    "                \n",
    "                    Q_estimate = (1-lr) * Q_estimate + 0\n",
    "                \n",
    "                end\n",
    "            \n",
    "                    Q_estimate = (1-lr) * Q_estimate + lr*reward[i]\n",
    "                \n",
    "            end\n",
    "    \n",
    "    end\n",
    "    \n",
    "     trial_data = DataFrame([sub,\n",
    "            block,\n",
    "            t,\n",
    "            force,\n",
    "            reward,\n",
    "            delay,\n",
    "            c,\n",
    "            reward_sum_store,\n",
    "            delay_sum_store,\n",
    "            av_reward_store,\n",
    "            opp_cost_store,\n",
    "            Q_estimate_store,\n",
    "            opp_cost_estimate_store])\n",
    "    \n",
    "    # detail names of variables - frustrating this is neccesary\n",
    "    names!(trial_data,[:sub,\n",
    "            :block,\n",
    "            :trial,\n",
    "            :force,\n",
    "            :reward,\n",
    "            :delay,\n",
    "            :choice,\n",
    "            :reward_sum,\n",
    "            :delay_sum,\n",
    "            :avreward_arithmetic,\n",
    "            :opp_cost_arithmetic,\n",
    "            :avreward_estimate,\n",
    "            :opp_cost_estimate])\n",
    "    \n",
    "    \n",
    "    # here if running em you can only return the likelihood\n",
    "    return -lik\n",
    "    \n",
    "    # but if you run in order to extract trials, subs etc then want to return this\n",
    "    #return (-lik, trial_data)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model for one subject\n",
    "\n",
    "##### aids debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225.2728336819827"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize parameter structures\n",
    "(df, subs, X, betas, sigma) = genVars(df, 3);\n",
    "\n",
    "# run model for sub 1\n",
    "model_subjective(betas,df[df[:sub].==subs[1],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run em to get best fit parameters for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter: 11\n",
      "betas: [0.87, 0.07, -1.81]\n",
      "sigma: [3.21 -0.01 1.28; -0.01 0.0 -0.0; 1.28 -0.0 2.15]\n",
      "change: [2.0e-5, 3.2e-5, -0.0, 3.3e-5, -0.000251, 8.0e-6, 0.000461, -0.000152, 0.0]\n",
      "max: 0.000461\n",
      " 79.288787 seconds (28.08 M allocations: 673.225 MiB, 0.38% gc time)\n"
     ]
    }
   ],
   "source": [
    "# initialized parameter structures (again)\n",
    "# note that some of the variables (e.g. betas, sigma) are entered and returned by em function \n",
    "(df, subs, X, betas, sigma) = genVars(df, 3);\n",
    "\n",
    "# run for full learner\n",
    "# x contains the parameters for each subject (note not the same as variable X)\n",
    "# l and h are per-subject likelihood and hessians\n",
    "@time (betas, sigma, x, l, h) = em(df, subs, X, betas, sigma, model_subjective; emtol=1e-3, parallel=true, full=true, quiet=false);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mccdf(d::UnivariateDistribution, X::AbstractArray) is deprecated, use ccdf.(d, X) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mccdf\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Distributions.Normal{Float64}, ::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1memerrors\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::DataFrames.DataFrame, ::Array{Int64,1}, ::SharedArray{Float64,2}, ::Array{Float64,3}, ::SharedArray{Float64,3}, ::Array{Float64,1}, ::Array{Float64,2}, ::Function\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/Dropbox/Daw_Lab/PreySelection/v103/models/model_subjective1beta1lr_initalise_8/em.jl:300\u001b[22m\u001b[22m\n",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m\n",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/Compat/src/Compat.jl:174\u001b[22m\u001b[22m\n",
      " [6] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/IJulia/src/execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [7] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [8] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[28], in expression starting on line 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.265902, 0.00305553, 0.218595], [0.00110202, 2.74585e-113, 1.46089e-16], [0.0707039 -0.00022396 0.0276314; -0.00022396 9.33624e-6 -8.61941e-5; 0.0276314 -8.61941e-5 0.0477838])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(standarderrors,pvalues,covmtx) = emerrors(df,subs,x,X,h,betas,sigma,model_subjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.00110202  \n",
       " 2.74585e-113\n",
       " 1.46089e-16 "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Model Statistics \n",
    "#### (IAIC, LOOCV, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4649.280934870067"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## model selection/comparison/scoring\n",
    "\n",
    "# laplace approximation to the aggregate log marginal likelihood of the whole dataset\n",
    "# marginalized over the individual params\n",
    "\n",
    "aggll = lml(x,l,h)\n",
    "\n",
    "# to compare this between models you need to correct for the group-level free parameters\n",
    "# either aic or bic\n",
    "\n",
    "aggll_ibic = ibic(x,l,h,betas,sigma,nrow(df))\n",
    "aggll_iaic = iaic(x,l,h,betas,sigma)\n",
    "\n",
    "# or you can compute unbiased per subject marginal likelihoods via subject-level cross validation\n",
    "# you can do paired t tests on these between models\n",
    "# these are also appropriate for SPM_BMS etc\n",
    "\n",
    "# takes ages so comment in when want to run, otherwise just use IAIC above\n",
    "\n",
    "#liks = loocv(df, subs, x, X, betas, sigma, model_subjective; emtol=1e-3, parallel=true, full=true)\n",
    "#aggll_loo = sum(liks)\n",
    "\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll: $aggll_iaic\\nloo nll:  $aggll_loo\")\n",
    "#println(\"\\n\\nraw nll:  $aggll\\nibic nll: $aggll_ibic\\niaic nll:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write loocv scores to csv file\n",
    "\n",
    "#### (if you have run this part above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put loocv scores into dataframe\n",
    " loocv_scores = DataFrame(sub = subs,\n",
    " liks = vec(liks));\n",
    "\n",
    "# save loocv scores to csv file\n",
    " writetable(\"loocv_scores.csv\", DataFrame(loocv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write per subject model parameters to csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mwritetable is deprecated, use CSV.write from the CSV package instead\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1m#writetable#185\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Bool, ::Char, ::Char, ::String, ::Bool, ::Function, ::String, ::DataFrames.DataFrame\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/DataFrames/src/deprecated.jl:69\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mwritetable\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::DataFrames.DataFrame\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/DataFrames/src/deprecated.jl:69\u001b[22m\u001b[22m\n",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m\n",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/Compat/src/Compat.jl:174\u001b[22m\u001b[22m\n",
      " [6] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/IJulia/src/execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [7] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/neil/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [8] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[31], in expression starting on line 12\n"
     ]
    }
   ],
   "source": [
    "# put parameters into variable d\n",
    "d=x';\n",
    "\n",
    "# now put parameters into dataframe\n",
    "params = DataFrame(sub = subs,\n",
    "intercept = vec(d[:,1]), \n",
    "beta = vec(d[:,2]),\n",
    "learning_rate_raw = vec(d[:,3]),\n",
    "learning_rate_transformed = vec(0.5 + 0.5*erf.(d[:,3] / sqrt(2))));\n",
    "\n",
    "# save parameters to csv file\n",
    "writetable(\"subject_params.csv\", DataFrame(params))\n",
    "\n",
    "#or: CSV.write(\"subject_params_full_learner.csv\",params_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run  model with these parameters for each subject to get trial by trial Q values\n",
    "##### Note: must rerun model with it set to return trial data (uncomment this)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you already have best fit parameters saved, can read in here (rather than running model to find)\n",
    "params = readtable(\"subject_params.csv\")\n",
    "head(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run model for each sub using best fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize parameter structures once again\n",
    "(df, subs, X, betas, sigma) = genVars(df, 3);\n",
    "\n",
    "# initalise this - will store all trial to trial parameters\n",
    "trial_data_compile = []\n",
    "\n",
    "# run model for each subject using best fit parameters\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = Array(params[x, [:intercept, :beta, :learning_rate_raw]])\n",
    "    data_sub = df[df[:sub].==subs[x], :]\n",
    "    \n",
    "    # run model using these parameters - note must have commented in the model to return all of these variables (and not only -lik)\n",
    "    (minus_li, trial_data) = model_subjective(betas_sub, data_sub)\n",
    "    \n",
    "    if x==1\n",
    "        \n",
    "        trial_data_compile = trial_data\n",
    "        \n",
    "    else\n",
    "        \n",
    "        append!(trial_data_compile, trial_data)\n",
    "        \n",
    "    end\n",
    " \n",
    "end\n",
    "\n",
    "# check these are all the same sizes\n",
    "print(size(df))\n",
    "print(size(trial_data_compile))\n",
    "\n",
    "# print header of data compile\n",
    "head(trial_data_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate probabilities of choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ProbAccept_ALL = []\n",
    "ProbReject_ALL = [] \n",
    "ProbAccept_minus_ProbReject_ALL = []\n",
    "\n",
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "    \n",
    "    # pull out optimal betas for subject - these are used in the model\n",
    "    # note: you want the unconverted learning score to be fed in\n",
    "    betas_sub = Array(params[x, [:intercept, :beta]])\n",
    "    \n",
    "    intercept = betas_sub[1] \n",
    "    beta = betas_sub[2]\n",
    "            \n",
    "    subset_data = trial_data_compile[trial_data_compile[:sub].==subs[x], :]\n",
    "    \n",
    "    n_trials = size(subset_data); n_trials = n_trials[1]\n",
    "\n",
    "    ProbAccept = zeros(n_trials)\n",
    "    ProbReject = zeros(n_trials)\n",
    "    ProbAccept_minus_ProbReject = zeros(n_trials)\n",
    "    \n",
    "    accept_value = subset_data[:reward]\n",
    "    reject_value = subset_data[:opp_cost_estimate]\n",
    "    choices = subset_data[:choice]\n",
    "    \n",
    "    for t = 1:n_trials\n",
    "                       \n",
    "        ProbAccept[t] = exp(0 + beta*accept_value[t])/(exp(0 + beta*accept_value[t]) + exp(intercept + beta*reject_value[t])) \n",
    "        ProbReject[t] = 1 - ProbAccept[t];\n",
    "        ProbAccept_minus_ProbReject[t] = ProbAccept[t] - ProbReject[t];\n",
    "         \n",
    "    end\n",
    "\n",
    "    ProbAccept_ALL = [ProbAccept_ALL; ProbAccept]\n",
    "    ProbReject_ALL = [ProbReject_ALL; ProbReject]\n",
    "    ProbAccept_minus_ProbReject_ALL = [ProbAccept_minus_ProbReject_ALL; ProbAccept_minus_ProbReject]\n",
    "    \n",
    "end\n",
    "\n",
    "#Now bung into data frame and merge with rest\n",
    "Q_probs = DataFrame([ProbAccept_ALL, \n",
    "        ProbReject_ALL, \n",
    "        ProbAccept_minus_ProbReject_ALL]) \n",
    "\n",
    "#annoying - must be a better way to do this\n",
    "names!(Q_probs, [:ProbAccept, \n",
    "        :ProbReject, \n",
    "        :ProbAccept_minus_ProbReject])\n",
    "\n",
    "# now merge the two dataframes together (note this overwrites previous full compile)\n",
    "trial_data_compile = hcat(trial_data_compile, Q_probs); #could also do just: [full_Q_compile Q_probs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to csv in model folder\n",
    "##### NOTE: after this note you must save as an xlsx file to run in matlab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writetable(\"trial_by_trial_values.csv\", DataFrame(trial_data_compile))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "println(\"intercept min: \", minimum(params[:intercept]))\n",
    "println(\"intercept max: \", maximum(params[:intercept]))\n",
    "println(\"beta min: \", minimum(params[:beta]))\n",
    "println(\"beta max: \", maximum(params[:beta]))\n",
    "println(\"lr min: \", minimum(params[:learning_rate_transformed]))\n",
    "println(\"lr max: \", maximum(params[:learning_rate_transformed]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [1, 2, 3]\n",
    "\n",
    "my_xticks = [\"intercept\",\"beta\", \"lr\"]\n",
    "\n",
    "y=[mean(params[:intercept]), mean(params[:beta]), mean(params[:learning_rate_transformed])]\n",
    "\n",
    "PyPlot.plt[:xticks](x, my_xticks)\n",
    "PyPlot.plt[:bar](x,y,color=\"#0f87bf\",align=\"center\",alpha=0.4)\n",
    "title(\"average parameter values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOTE: intercept in the model is put on the value of rejecting: hence a negative value suggests a bias away from rejecting (the value of rejecting is devalued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PyPlot.plt[:hist](params[:intercept],10)\n",
    "title(\"Histrogram of intercept parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PyPlot.plt[:hist](params[:beta],10)\n",
    "title(\"Histrogram of beta value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PyPlot.plt[:hist](params[:learning_rate_transformed],10)\n",
    "title(\"Histrogram of learning parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PyPlot.plt[:scatter](params[:beta],params[:learning_rate_transformed])\n",
    "title(\"learning parameters: beta vs lr\")\n",
    "xlabel(\"beta\")\n",
    "ylabel(\"learning_rate\")\n",
    "\n",
    "println(\"correlation: \", cor(params[:beta],params[:learning_rate_transformed]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "    \n",
    "    subset_data_all = trial_data_compile[trial_data_compile[:sub].==current_sub, :]\n",
    "    \n",
    "    #subset_data_b1 = \n",
    "    #subset_data_b2  = \n",
    "    \n",
    "    X = subset_data_all[:trial]\n",
    "    Y = subset_data_all[:opp_cost_arithmetic]\n",
    "    \n",
    "    subplot(7,7,x)\n",
    "\n",
    "    PyPlot.plt[:scatter](X,Y,s=0.5)\n",
    "            \n",
    "end\n",
    "\n",
    "suptitle(\"Arithmetic opportunity cost over time for each sub\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### opp cost fluctuates trial by trial a lot depending on the options (their delay) as well as the average reward rate \n",
    "#### hence why it looks like two lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "    \n",
    "    subset_data_all = trial_data_compile[trial_data_compile[:sub].==current_sub, :]\n",
    "    \n",
    "    \n",
    "    X = subset_data_all[:trial]\n",
    "    Y = subset_data_all[:opp_cost_estimate]\n",
    "    \n",
    "    subplot(7,7,x)\n",
    "\n",
    "    PyPlot.plt[:scatter](X,Y,s=0.5)\n",
    "            \n",
    "end\n",
    "\n",
    "suptitle(\"Estimated opportunity cost over time for each sub\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "    \n",
    "    subset_data_all = trial_data_compile[trial_data_compile[:sub].==current_sub, :]\n",
    "    \n",
    "    #subset_data_b1 = \n",
    "    #subset_data_b2  = \n",
    "    \n",
    "    X = subset_data_all[:trial]\n",
    "    Y = subset_data_all[:avreward_arithmetic]\n",
    "    \n",
    "    subplot(7,7,x)\n",
    "\n",
    "    PyPlot.plt[:scatter](X,Y,s=0.5)\n",
    "            \n",
    "end\n",
    "\n",
    "suptitle(\"Arithmetic average reward rate over time for each sub\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x = 1:length(subs)\n",
    "\n",
    "    current_sub = subs[x];\n",
    "    \n",
    "    subset_data_all = trial_data_compile[trial_data_compile[:sub].==current_sub, :]\n",
    "    \n",
    "    #subset_data_b1 = \n",
    "    #subset_data_b2  = \n",
    "    \n",
    "    X = subset_data_all[:trial]\n",
    "    Y = subset_data_all[:avreward_estimate]\n",
    "    \n",
    "    subplot(7,7,x)\n",
    "\n",
    "    PyPlot.plt[:scatter](X,Y,s=0.5)\n",
    "            \n",
    "end\n",
    "\n",
    "suptitle(\"Estimated average reward rate over time for each sub\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
